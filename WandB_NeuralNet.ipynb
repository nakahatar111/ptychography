{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "O_j0aBVqc7St",
        "tags": []
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ej_xoH40c1gz"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cupy as cp\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import wandb\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "HyperParameter Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "ADAM_LR = 0.000018\n",
        "BETAS = (0.75, 0.999)\n",
        "NUM_EPOCHS = 3000\n",
        "\n",
        "wandb_config = {\n",
        "    \"Learning_Rate\": ADAM_LR,\n",
        "    \"Betas\": BETAS,\n",
        "    \"Num_Epochs\": NUM_EPOCHS\n",
        "}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hyper Parameter Sweep Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    'method': 'random'\n",
        "}\n",
        "\n",
        "metric = {\n",
        "    'name' : 'loss',\n",
        "    'goal' : 'minimize'\n",
        "}\n",
        "\n",
        "\n",
        "parameters_dict = {\n",
        "    'learning_rate': {\n",
        "        'values': [0.000050, 0.000040, 0.000030, 0.000020, 0.000010, 0.000044, 0.000035, 0.000025, 0.000015]\n",
        "    },\n",
        "    'beta_val1': {\n",
        "        'distribution': 'uniform',\n",
        "        'min': 0.5,\n",
        "        'max': 0.99999\n",
        "    },\n",
        "    'beta_val2': {\n",
        "        'distribution': 'uniform',\n",
        "        'min': 0.5,\n",
        "        'max': 0.99999\n",
        "    },\n",
        "    'epochs': {\n",
        "        'value': 3000\n",
        "    }\n",
        "    \n",
        "}\n",
        "sweep_config['metric'] = metric\n",
        "sweep_config['parameters'] = parameters_dict"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Weights and Biases Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msrsbingresearch\u001b[0m (\u001b[33mbingsrs\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.login()\n",
        "\n",
        "# sweep_id = wandb.sweep(sweep_config, project=\"ePIE - HyperParameter Sweep\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "diff_grid = np.load('dataset/diff_grid.npz')['arr_0']\n",
        "label = np.load('dataset/diffraction_label.npz')['arr_0']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "svjrw-7_6sxN"
      },
      "source": [
        "Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "X-bCjkJK6p2B"
      },
      "outputs": [],
      "source": [
        "def conv(in_channels, out_channels):\n",
        "  return nn.Sequential(\n",
        "    nn.Conv2d(in_channels, out_channels, kernel_size=5, stride=3, padding=1),\n",
        "    nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
        "    nn.BatchNorm2d(out_channels),\n",
        "  )\n",
        "  \n",
        "def conv_max(in_channels, out_channels):\n",
        "  return nn.Sequential(\n",
        "    nn.Conv2d(in_channels, out_channels, kernel_size=5, stride=3, padding=1),\n",
        "    nn.MaxPool2d(3, stride=2),\n",
        "    nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
        "    nn.BatchNorm2d(out_channels),\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3ZgO6-gE6y7y"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.block1 = conv(1, 16)\n",
        "    self.block2 = conv_max(16, 32)\n",
        "    self.block3 = conv_max(32, 64)\n",
        "    self.block4 = conv_max(64, 128)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.block1(x)\n",
        "    x = self.block2(x)\n",
        "    x = self.block3(x)\n",
        "    x = self.block4(x)\n",
        "    return x"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WcTLp1_E7HdD"
      },
      "source": [
        "Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "whr7Ccl17JVG"
      },
      "outputs": [],
      "source": [
        "def convTrans(in_channels, out_channels):\n",
        "  return nn.Sequential(\n",
        "    nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=2),\n",
        "    #nn.ReLU(inplace = True),\n",
        "    nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
        "  )\n",
        "\n",
        "def up_conv(in_channels, out_channels, padding):\n",
        "  return nn.Sequential(\n",
        "    nn.ConvTranspose2d(in_channels, out_channels, kernel_size=5, stride=2, padding=padding),\n",
        "    #nn.ReLU(inplace = True),\n",
        "    nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
        "    nn.BatchNorm2d(out_channels),\n",
        "    nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QZZne5jP8VgX"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.block1 = up_conv(128, 64, 1)\n",
        "    self.block2 = convTrans(64, 32)\n",
        "    self.block3 = up_conv(32, 16, 2)\n",
        "    self.block4 = convTrans(16, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.block1(x)\n",
        "    x = self.block2(x)\n",
        "    x = self.block3(x)\n",
        "    x = self.block4(x)\n",
        "    return x"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mU0oV2m88Xvw"
      },
      "source": [
        "Encoder-Decoder Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "k3YxOZ4J8XSd"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "    self.encoder = Encoder()\n",
        "    self.phase_decoder = Decoder()\n",
        "    self.amp_decoder = Decoder()\n",
        "    self.tanh = nn.Tanh()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, diffraction):\n",
        "    latent_z = self.encoder(diffraction)\n",
        "    phase = self.tanh(self.phase_decoder(latent_z))\n",
        "    phase = phase*cp.pi\n",
        "    amp = self.sigmoid(self.amp_decoder(latent_z))\n",
        "    return phase, amp"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2wB8dtTO-0_m"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "a11Trf_8-U4P"
      },
      "outputs": [],
      "source": [
        "lossfn =  nn.MSELoss()\n",
        "def ModelLoss(preds1, targets1, preds2, targets2):\n",
        "  loss1 = lossfn(preds1, targets1)\n",
        "  loss2 = lossfn(preds2, targets2)\n",
        "  # loss2 = nn.functional.binary_cross_entropy(preds2, targets2, reduction='mean')\n",
        "  return loss1, loss2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "PtychoModel = Model().to(device)\n",
        "PtychoModel.load_state_dict(torch.load('models/overfit4.pth'))\n",
        "diff = torch.tensor(diff_grid,device=device).float()\n",
        "phase = torch.tensor(label[:, 0],device=device).float()\n",
        "amp = torch.tensor(label[:, 1],device=device).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rZ8wjvBO-uwK"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "  # Look into Scheduler: (varies the learning rate of optimizer) scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=, max_lr=, step_size_up=)\n",
        "  optimizer = torch.optim.Adam(PtychoModel.parameters(), lr=ADAM_LR, betas=BETAS)\n",
        "  for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "    PtychoModel.train()\n",
        "    phase_pred, amp_pred = PtychoModel(diff)\n",
        "    loss1, loss2 = ModelLoss(phase_pred, phase, amp_pred, amp)\n",
        "    loss = loss1+loss2\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (epoch+1) % 100 == 0:\n",
        "      print(\"Epoch: \", (epoch+1), \"Training Loss: \", round(loss.item(), 5), round(loss1.item(), 7), round(loss2.item(), 7))\n",
        "    wandb.log({\n",
        "      'loss': round(loss.item(),3),\n",
        "      'loss1': round(loss1.item(),4),\n",
        "      'loss2': round(loss2.item(),4)\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "wandb version 0.13.8 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.7"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/nburzyn1/ePIE/ptychography/wandb/run-20230112_095546-2eufk400</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/bingsrs/ptychography/runs/2eufk400\" target=\"_blank\">rural-darkness-5</a></strong> to <a href=\"https://wandb.ai/bingsrs/ptychography\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nburzyn1/.local/lib/python3.6/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "/home/nburzyn1/.local/lib/python3.6/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([4, 1, 650, 650])) that is different to the input size (torch.Size([1, 1, 650, 650])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ],
      "source": [
        "# wandb.agent(sweep_id, train, count = 10)\n",
        "wandb.init(config=wandb_config)\n",
        "train()\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PtychoModel.eval()\n",
        "phase_pred, amp_pred = PtychoModel(diff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "ruby"
        }
      },
      "outputs": [],
      "source": [
        "f, ax = plt.subplots(4,4, figsize=(12, 12), facecolor='white')\n",
        "ax[0,0].set_ylabel('PtychoNeuralNetwork', fontsize = 12.0)\n",
        "ax[1,0].set_ylabel('E-Pie (300 Iterations)', fontsize = 12.0)\n",
        "ax[2,0].set_ylabel('PtychoNeuralNetwork', fontsize = 12.0)\n",
        "ax[3,0].set_ylabel('E-Pie (300 Iterations)', fontsize = 12.0)\n",
        "\n",
        "ax[0,0].imshow(phase_pred[0].cpu().detach().numpy().reshape((650,650)))\n",
        "ax[0,1].imshow(phase_pred[1].cpu().detach().numpy().reshape((650,650)))\n",
        "ax[0,2].imshow(phase_pred[2].cpu().detach().numpy().reshape((650,650)))\n",
        "ax[0,3].imshow(phase_pred[3].cpu().detach().numpy().reshape((650,650)))\n",
        "ax[1,0].imshow(phase[0].cpu().detach().numpy().reshape((650,650)))\n",
        "ax[1,1].imshow(phase[1].cpu().detach().numpy().reshape((650,650)))\n",
        "ax[1,2].imshow(phase[2].cpu().detach().numpy().reshape((650,650)))\n",
        "ax[1,3].imshow(phase[3].cpu().detach().numpy().reshape((650,650)))\n",
        "ax[2,0].imshow(amp_pred[0].cpu().detach().numpy().reshape((650,650)))\n",
        "ax[2,1].imshow(amp_pred[1].cpu().detach().numpy().reshape((650,650)))\n",
        "ax[2,2].imshow(amp_pred[2].cpu().detach().numpy().reshape((650,650)))\n",
        "ax[2,3].imshow(amp_pred[3].cpu().detach().numpy().reshape((650,650)))\n",
        "ax[3,0].imshow(amp[0].cpu().detach().numpy().reshape((650,650)))\n",
        "ax[3,1].imshow(amp[1].cpu().detach().numpy().reshape((650,650)))\n",
        "ax[3,2].imshow(amp[2].cpu().detach().numpy().reshape((650,650)))\n",
        "ax[3,3].imshow(amp[3].cpu().detach().numpy().reshape((650,650)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "f, ax = plt.subplots(2,2, figsize=(11, 10), facecolor='white')\n",
        "ax[0,0].set_ylabel('PtychoNeuralNetwork', fontsize = 20.0)\n",
        "ax[0,0].set_title('Amplitude', fontsize = 20.0)\n",
        "ax[0,0].imshow(phase_pred[0].cpu().detach().numpy().reshape((650,650)))\n",
        "ax[0,1].set_title('Phase', fontsize = 20.0)\n",
        "ax[0,1].imshow(amp_pred[0].cpu().detach().numpy().reshape((650,650)))\n",
        "ax[1,0].set_ylabel('E-Pie (300 Iterations)', fontsize = 20.0)\n",
        "ax[1,0].imshow(phase[0].cpu().detach().numpy().reshape((650,650)))\n",
        "ax[1,1].imshow(amp[0].cpu().detach().numpy().reshape((650,650)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(PtychoModel.state_dict(), 'overfit4.pth')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
