{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import Encoder_Decoder_Model\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff_grid = np.load('dataset/diff_grid.npz')['arr_0'] # Non-compressed 7100x7100 diff grid\n",
    "diff_grid = np.load('dataset/compressed_diff_grid.npz')['arr_0'] # Compressed 1775x1775 diff grid\n",
    "label = np.load('dataset/norm_diffraction_label.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossfn =  nn.BCELoss(reduction='mean')\n",
    "\n",
    "def ModelLoss(preds1, targets1, preds2, targets2):\n",
    "  loss1 = lossfn(preds1, targets1)\n",
    "  loss2 = lossfn(preds2, targets2)\n",
    "  return loss1, loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PtychoModel = Encoder_Decoder_Model.Model().to(device)\n",
    "PtychoModel.load_state_dict(torch.load('models/MSE_10000.pth'))\n",
    "diff = torch.tensor(diff_grid,device=device).float()\n",
    "phase = torch.tensor(label[:, 0],device=device).float()\n",
    "amp = torch.tensor(label[:, 1],device=device).float()\n",
    "LR = 0.00013\n",
    "step_size = 8000\n",
    "optimizer = torch.optim.AdamW(PtychoModel.parameters(), lr=LR, betas=(0.59418, 0.8699))\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=LR/10, max_lr=LR, step_size_up=step_size, cycle_momentum=False, mode='triangular2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "  PtychoModel.train()\n",
    "  phase_pred, amp_pred = PtychoModel(diff)\n",
    "  loss1, loss2 = ModelLoss(phase_pred, phase, amp_pred, amp)\n",
    "  loss = loss1 + loss2\n",
    "\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  scheduler.step()\n",
    "\n",
    "  if((epoch+1) % 50 == 0):\n",
    "    print(\"Epoch: \", (epoch+1), \" Training Loss: \", round(loss.item(), 5), \" L1: \",round(loss1.item(), 7),\" L2: \", round(loss2.item(), 7))\n",
    "\n",
    "torch.save(PtychoModel.state_dict(), 'models/model_name.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PtychoModel.eval()\n",
    "phase_pred, amp_pred = PtychoModel(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(4,4, figsize=(12, 12), facecolor='white')\n",
    "ax[0,0].set_ylabel('PtychoNeuralNetwork', fontsize = 12.0)\n",
    "ax[1,0].set_ylabel('E-Pie (300 Iterations)', fontsize = 12.0)\n",
    "ax[2,0].set_ylabel('PtychoNeuralNetwork', fontsize = 12.0)\n",
    "ax[3,0].set_ylabel('E-Pie (300 Iterations)', fontsize = 12.0)\n",
    "\n",
    "ax[0,0].imshow(phase_pred[0].cpu().detach().numpy().reshape((650,650)))\n",
    "ax[0,1].imshow(phase_pred[1].cpu().detach().numpy().reshape((650,650)))\n",
    "ax[0,2].imshow(phase_pred[2].cpu().detach().numpy().reshape((650,650)))\n",
    "ax[0,3].imshow(phase_pred[3].cpu().detach().numpy().reshape((650,650)))\n",
    "ax[1,0].imshow(phase[0].cpu().detach().numpy().reshape((650,650)))\n",
    "ax[1,1].imshow(phase[1].cpu().detach().numpy().reshape((650,650)))\n",
    "ax[1,2].imshow(phase[2].cpu().detach().numpy().reshape((650,650)))\n",
    "ax[1,3].imshow(phase[3].cpu().detach().numpy().reshape((650,650)))\n",
    "ax[2,0].imshow(amp_pred[0].cpu().detach().numpy().reshape((650,650)))\n",
    "ax[2,1].imshow(amp_pred[1].cpu().detach().numpy().reshape((650,650)))\n",
    "ax[2,2].imshow(amp_pred[2].cpu().detach().numpy().reshape((650,650)))\n",
    "ax[2,3].imshow(amp_pred[3].cpu().detach().numpy().reshape((650,650)))\n",
    "ax[3,0].imshow(amp[0].cpu().detach().numpy().reshape((650,650)))\n",
    "ax[3,1].imshow(amp[1].cpu().detach().numpy().reshape((650,650)))\n",
    "ax[3,2].imshow(amp[2].cpu().detach().numpy().reshape((650,650)))\n",
    "ax[3,3].imshow(amp[3].cpu().detach().numpy().reshape((650,650)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.9 (default, Jun 29 2022, 11:45:57) \n[GCC 8.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
