{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "O_j0aBVqc7St",
        "tags": []
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ej_xoH40c1gz"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rnakaha2/.local/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import amp_Model\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Data(Dataset):\n",
        "  def __init__(self):\n",
        "    self.diff_grid = torch.tensor(np.load('../dataset/compressed_diff_grid.npz')['arr_0']).float()\n",
        "    labels = np.load('../dataset/norm_diffraction_label.npz')['arr_0']\n",
        "    self.amp = torch.tensor(labels[:, 1]).float()\n",
        "  def __len__(self):\n",
        "    return self.diff_grid.shape[0]\n",
        "  def __getitem__(self, i):\n",
        "    return (self.diff_grid[i], self.amp[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "trn_ds = Data()\n",
        "trn_dl = DataLoader(trn_ds, batch_size=4, shuffle=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2wB8dtTO-0_m"
      },
      "source": [
        "Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "a11Trf_8-U4P"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rnakaha2/.local/lib/python3.6/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `MS_SSIM` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "  warnings.warn(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Testing Different Loss functions\n",
        "\n",
        "#from torchmetrics import PeakSignalNoiseRatio\n",
        "from torchmetrics import MultiScaleStructuralSimilarityIndexMeasure\n",
        "#lossfn =  nn.L1Loss()\n",
        "#lossfn =  nn.MSELoss()\n",
        "#lossfn = PeakSignalNoiseRatio(data_range=1.0).to(device)\n",
        "lossfn =  MultiScaleStructuralSimilarityIndexMeasure().to(device) # must be positive number\n",
        "#lossfn =  nn.BCELoss(reduction='mean')\n",
        "\n",
        "def ModelLoss(pred1, target1):\n",
        "  loss1 = lossfn(pred1, target1)\n",
        "  return loss1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, input, target1, optimizer, criterion, scheduler=None):\n",
        "  model.train()\n",
        "  amp_pred = model(input)\n",
        "  loss = criterion(amp_pred, target1)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  if(scheduler != None):\n",
        "    scheduler.step()\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def hyperparameter(num_epochs, learning_rate, plot=True):\n",
        "  if plot:\n",
        "    plt.subplot(2, 1, 2, facecolor='white')\n",
        "    plt.title('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "\n",
        "\n",
        "  PtychoModel = amp_Model.Model().to(device)\n",
        "  torch.save(PtychoModel.state_dict(), 'initial.pth')\n",
        "  criterion = ModelLoss\n",
        "  \n",
        "  for l_rate in learning_rate:\n",
        "    PtychoModel.load_state_dict(torch.load('initial.pth'))\n",
        "    optimizer = optim.AdamW(PtychoModel.parameters(), lr=l_rate, betas=(0.396, 0.899))\n",
        "    if plot:\n",
        "      loss_hist = []\n",
        "    for epoch in range(num_epochs):\n",
        "      for bx, data in enumerate(trn_dl):\n",
        "        diff, amp = data\n",
        "        diff, amp = diff.to(device), amp.to(device)\n",
        "        loss = train_model(PtychoModel, diff, amp, optimizer, criterion)\n",
        "\n",
        "        if((epoch+1) % 200 == 0):\n",
        "          print(\"Epoch: \", (epoch+1), \" Training Loss: \", round(loss.item(), 5))\n",
        "        if(plot and ((epoch+1) % 50 == 0)):\n",
        "          loss_hist.append(loss.item())\n",
        "    if plot:\n",
        "      plt.plot(loss_hist, '-', label= 'trn_acc:'+str(l_rate))\n",
        "  if plot:\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.gcf().set_size_inches(15, 15)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 1.77 GiB already allocated; 5.81 MiB free; 1.82 GiB reserved in total by PyTorch)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-5273d6c0ec55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.0002\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.00001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.00005\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhyperparameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-ddf151d0b444>\u001b[0m in \u001b[0;36mhyperparameter\u001b[0;34m(num_epochs, learning_rate, plot)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mdiff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mdiff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPtychoModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-58a7687e4166>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, input, target1, optimizer, criterion, scheduler)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mamp_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamp_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-0998573c4bd1>\u001b[0m in \u001b[0;36mModelLoss\u001b[0;34m(pred1, target1)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mModelLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mloss1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mloss1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchmetrics/metric.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;31m# restore context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchmetrics/metric.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0mshould_unsync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_unsync\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             ):\n\u001b[0;32m--> 440\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_computed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_squeeze_if_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchmetrics/image/ssim.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbetas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         )\n",
            "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchmetrics/functional/image/ssim.py\u001b[0m in \u001b[0;36m_multiscale_ssim_compute\u001b[0;34m(preds, target, gaussian_kernel, sigma, kernel_size, reduction, data_range, k1, k2, betas, normalize)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         sim, contrast_sensitivity = _get_normalized_sim_and_cs(\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgaussian_kernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         )\n\u001b[1;32m    386\u001b[0m         \u001b[0msim_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchmetrics/functional/image/ssim.py\u001b[0m in \u001b[0;36m_get_normalized_sim_and_cs\u001b[0;34m(preds, target, gaussian_kernel, sigma, kernel_size, reduction, data_range, k1, k2, normalize)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0mk1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mk2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mreturn_contrast_sensitivity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     )\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnormalize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchmetrics/functional/image/ssim.py\u001b[0m in \u001b[0;36m_ssim_compute\u001b[0;34m(preds, target, gaussian_kernel, sigma, kernel_size, reduction, data_range, k1, k2, return_full_image, return_contrast_sensitivity)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_contrast_sensitivity\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mcontrast_sensitivity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupper\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0mcontrast_sensitivity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontrast_sensitivity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_h\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpad_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_w\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpad_w\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         return reduce(ssim_idx.reshape(ssim_idx.shape[0], -1).mean(-1), reduction), reduce(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 1.77 GiB already allocated; 5.81 MiB free; 1.82 GiB reserved in total by PyTorch)"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "epochs = 3000\n",
        "lr = [0.001,0.0002, 0.00001, 0.00005]\n",
        "hyperparameter(epochs, lr, True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Train Using Best Hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model, lr, num_epochs, step_size=5000):\n",
        "  plt.subplot(2, 1, 2, facecolor='white')\n",
        "  plt.title('Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  loss_hist = []\n",
        "  rec_freq = num_epochs//60\n",
        "  \n",
        "  optimizer = torch.optim.AdamW(model.parameters(), lr=lr, betas=(0.3, 0.79))\n",
        "  scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=lr/10, max_lr=lr, step_size_up=step_size, cycle_momentum=False, mode='triangular2')\n",
        "  criterion = ModelLoss\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    for bx, data in enumerate(trn_dl):\n",
        "      diff, amp = data\n",
        "      diff, amp = diff.to(device), amp.to(device)\n",
        "      loss = train_model(model, diff, amp, optimizer, criterion, scheduler)\n",
        "      if((epoch+1) % 200 == 0):\n",
        "        print(\"Epoch: \", (epoch+1), \" Training Loss: \", round(loss.item(), 5))\n",
        "      if((epoch+1) % rec_freq == 0):\n",
        "          loss_hist.append(loss.item())\n",
        "  plt.plot(loss_hist, '-', label= 'trn_acc:'+str(lr))\n",
        "  plt.legend(loc='upper right')\n",
        "  plt.gcf().set_size_inches(15, 15)\n",
        "  plt.show()\n",
        "  \n",
        "  torch.save(model.state_dict(), 'amp1.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:  200  Training Loss:  0.6879\n",
            "Epoch:  400  Training Loss:  0.6871\n",
            "Epoch:  600  Training Loss:  0.68618\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-f183172999ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mPtychoModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mamp_Model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#PtychoModel.load_state_dict(torch.load('amp1.pth'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPtychoModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0003\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-160ea941ef7d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, lr, num_epochs, step_size)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m       \u001b[0mdiff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mdiff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "PtychoModel = amp_Model.Model().to(device)\n",
        "#PtychoModel.load_state_dict(torch.load('amp1.pth'))\n",
        "train(PtychoModel, 0.0003, 10000)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize(model):\n",
        "  diff_grid = np.load('../dataset/compressed_diff_grid.npz')['arr_0']\n",
        "  label = np.load('../dataset/norm_diffraction_label.npz')['arr_0']\n",
        "  diff = torch.tensor(diff_grid,device=device).float()\n",
        "  amp = torch.tensor(label[:, 1],device=device).float()\n",
        "  model.eval()\n",
        "  amp_pred = model(diff)\n",
        "  \n",
        "  f, ax = plt.subplots(2,4, figsize=(6, 12), facecolor='white')\n",
        "  ax[0,0].set_ylabel('PtychoNeuralNetwork', fontsize = 12.0)\n",
        "  ax[1,0].set_ylabel('E-Pie (300 Iterations)', fontsize = 12.0)\n",
        "\n",
        "  ax[0,0].imshow(amp_pred[0].cpu().detach().numpy().reshape((650,650)))\n",
        "  ax[0,1].imshow(amp_pred[1].cpu().detach().numpy().reshape((650,650)))\n",
        "  ax[0,2].imshow(amp_pred[2].cpu().detach().numpy().reshape((650,650)))\n",
        "  ax[0,3].imshow(amp_pred[3].cpu().detach().numpy().reshape((650,650)))\n",
        "  ax[1,0].imshow(amp[0].cpu().detach().numpy().reshape((650,650)))\n",
        "  ax[1,1].imshow(amp[1].cpu().detach().numpy().reshape((650,650)))\n",
        "  ax[1,2].imshow(amp[2].cpu().detach().numpy().reshape((650,650)))\n",
        "  ax[1,3].imshow(amp[3].cpu().detach().numpy().reshape((650,650)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'amp_Model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-8863776390ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mPtychoModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mamp_Model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mPtychoModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'amp1.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPtychoModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'amp_Model' is not defined"
          ]
        }
      ],
      "source": [
        "PtychoModel = amp_Model.Model().to(device)\n",
        "PtychoModel.load_state_dict(torch.load('amp1.pth'))\n",
        "visualize(PtychoModel)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
